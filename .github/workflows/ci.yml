# .github/workflows/ci.yml

name: dbt CI/CD

on:
  pull_request:
    branches: [ main ]
    paths:
    - 'dbt/models/**'        # <-- Add 'dbt/'
    - 'dbt/macros/**'        # <-- Add 'dbt/'
    - 'dbt/seeds/**'         # <-- Add 'dbt/'
    - 'dbt/snapshots/**'     # <-- Add 'dbt/'
    - 'dbt/tests/**'         # <-- Add 'dbt/'
    - 'dbt/scripts/**'       # <-- Add 'dbt/'
    - '.github/workflows/ci.yml' # This path is correct as it's at the root

jobs:
  dbt-ci:
    name: Run dbt quality checks
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: 1. Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Required for state-based selection

      - name: 2. Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 3. Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r dbt/scripts/requirements.txt 
          pip install dbt-snowflake

      - name: 4. Configure dbt Profile for CI
        run: |
          mkdir -p ~/.dbt
          cat > ~/.dbt/profiles.yml <<EOF
          inherra_dbt:
            target: ci
            outputs:
              ci:
                type: snowflake
                account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
                user: ${{ secrets.SNOWFLAKE_USER }}
                private_key: '${{ secrets.SNOWFLAKE_PRIVATE_KEY }}'
                role: ${{ secrets.SNOWFLAKE_ROLE }}
                database: ${{ secrets.SNOWFLAKE_DATABASE }}
                warehouse: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
                schema: ci_${{ github.run_id }}  # Unique schema per run
                threads: 4
                transient: true
          EOF

      - name: 5. Configure .env for Python Script
        # This step is critical for the schema generator script to connect.
        run: |
          echo "
          SNOWFLAKE_USER=${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PRIVATE_KEY_PATH=~/.ssh/dbt_github_key.p8
          SNOWFLAKE_ACCOUNT=${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_ROLE=${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_WAREHOUSE=${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE=${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA=dbt_aodukale # The Python script still needs to read from the dev schema
          " > .env
          
      - name: 6. Store Private Key for Python Script
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SNOWFLAKE_PRIVATE_KEY }}" > ~/.ssh/dbt_github_key.p8

      - name: 7. Generate schema.yml from source of truth
        run: python scripts/generate_schema_yml.py
        working-directory: ./dbt 

      - name: 8. Install dbt dependencies
        run: dbt deps
        working-directory: ./dbt 

      - name: 9. Run dbt build on modified resources
        env:
          DBT_USE_COLORS: false
        run: dbt build --select state:modified+ --target ci --fail-fast
        working-directory: ./dbt

      - name: 10. Upload dbt artifacts
        if: always() # Always run this step to capture artifacts on failure
        uses: actions/upload-artifact@v4
        with:
          name: dbt-run-artifacts
          path: |
            dbt/target/run_results.json # <-- Add 'dbt/'
            dbt/target/manifest.json    # <-- Add 'dbt/