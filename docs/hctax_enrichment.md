Project Inherra: Real Estate Signal Enrichment Pipeline
Version: 2.0
Last Updated: June 21, 2025
Primary Author: [Your Name] & AI Assistant

1. Project Overview
This pipeline is the core of Project Inherra, a real estate intelligence engine designed to identify and enrich high-intent property leads. It automates the process of taking raw probate data, matching it to property records, and enriching it with detailed tax, property, and contact information.

The goal is to transform a simple list of names into a fully vetted, scored, and actionable lead list, ready for an acquisitions team.

2. System Architecture & Workflow
The pipeline operates in two main stages, using two separate Python scripts. This separation ensures modularity and makes debugging easier.

Stage 1: HCAD Enrichment
Script: script4_hcad_enrichment.py (or similar)

Input: A CSV file containing probate and Real Property (RP) data.

Process:

Takes decedent and RP data as input.

Scrapes the Harris County Appraisal District (HCAD) website (hcad.org).

Performs fuzzy name matching to link probate leads to property owners.

Assigns a match confidence score and a crucial hcad_owner_match_type.

Enriches the data with detailed property DNA (bedrooms, square footage, building materials, etc.).

Output: A detailed CSV file (e.g., script4_hcad_enriched_..._.csv) saved to the HCAD_Enrichment_Extractions folder.

Stage 2: HCTAX & Contact Enrichment (This Project's Script)
Script: production_enrichment_script_final.py

Input: The latest CSV file generated by the Stage 1 script. It finds this automatically.

Process:

HCTAX Scrape: Scrapes the Harris County Tax Office (hctax.net) for financial signals like tax delinquency, assessed values, and mailing addresses.

Contact Targeting: Applies a 4-tier logic model to determine the best person to contact (owner_contact_name) based on the match quality from Stage 1.

Apify API Call: For high-quality leads (Tiers A & B), it calls the Apify API to perform on-demand skip-tracing, retrieving phone numbers and email addresses.

Final Structuring: Sorts all 100+ columns into a definitive 6-Zone "Story Arc" for maximum readability.

Output: Generates two final files in the HCAD Tax Enrichment folder.

3. Setup & Installation
To run this pipeline, you need a Python environment with several libraries installed.

Step 1: Install Python Libraries
Open your terminal or command prompt and run the following command:

pip install pandas requests openpyxl

Step 2: Install Playwright
This pipeline uses Playwright to control a web browser for scraping.

Install the Playwright library:

pip install playwright

Install the necessary browser drivers (this will download a browser instance for Playwright to use):

playwright install

4. Configuration
Before running the production_enrichment_script_final.py, you must configure a few variables at the top of the file.

APIFY_API_TOKEN: Your personal Apify API key.

How to find it: Log in to Apify > Settings > Integrations.

APIFY_TASK_ID: The unique identifier for the Apify Actor or Task you want to run for skip-tracing.

How to find it: Go to the Task's page in the Apify Console. The ID is in the URL (e.g., https://console.apify.com/tasks/YOUR_TASK_ID) or on the API tab.

INPUT_DATA_FOLDER: The full path to the folder where the Stage 1 script saves its output.

Default: /Users/ayoodukale/Documents/Inherra/Python/Inherra scraper/HCAD_Enrichment_Extractions

OUTPUT_FOLDER: The name of the folder where the final files will be saved.

Default: HCAD Tax Enrichment

5. How to Run the Pipeline
Run the Stage 1 Script: Execute your HCAD enrichment script first. Ensure it successfully creates a new CSV file in the INPUT_DATA_FOLDER.

Configure the Stage 2 Script: Open production_enrichment_script_final.py and ensure your APIFY_API_TOKEN and APIFY_TASK_ID are set correctly.

Run the Stage 2 Script: Execute the script from your terminal:

python production_enrichment_script_final.py

The script will automatically find the latest input file, run the entire HCTAX and Apify enrichment process, and save the final output files.

6. Output Files
The pipeline generates two files with the same timestamp, each designed for a specific purpose:

1. The Formatted Excel File (.xlsx)
Filename: production_enriched_[timestamp].xlsx

Purpose: For human analysis. This file is for you and your acquisitions team.

Features:

6-Zone Story Arc: Columns are grouped under merged headers ("Lead Triage," "Core People & Property," etc.) for at-a-glance understanding.

Frozen Panes: The first two rows (zones and headers) and the first two columns are frozen for easy scrolling.

Styled Headers: Headers are colored and bolded for clarity.

2. The Clean CSV File (.csv)
Filename: production_enriched_[timestamp].csv

Purpose: For system integration.

Features:

Raw Data: Contains the exact same data as the Excel file but with no formatting.

Single Header Row: A simple, clean header row makes it easy to import into other systems like Airtable, dbt, Snowflake, or other Apify actors.

7. Troubleshooting
ModuleNotFoundError: No module named 'openpyxl': This means a required library for writing Excel files is missing. Run pip install openpyxl.

Apify API Errors (401 or 403): This almost always means your APIFY_API_TOKEN is incorrect or has expired. Double-check it in the script.

Apify API Errors (404): This usually means the APIFY_TASK_ID is incorrect. Verify the ID in your Apify console.